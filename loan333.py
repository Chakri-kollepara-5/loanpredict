# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cvMbHAZPu4S6liKt27mjqr6p1s5RUz_o
"""

import pandas as pd

# Load the CSV file
file_path = "/content/train_u6lujuX_CVtuZ9i (1).csv"  # Update path if needed
df = pd.read_csv(file_path)

# Display the first few rows
df.head()

df.isnull().sum()

df.fillna("null", inplace=True)  # Replace 'value' with appropriate strategy

df.info()

df.describe()

df.columns

df.drop_duplicates(inplace=True)

!pip install pandas matplotlib seaborn

# Importing modules
from IPython import get_ipython
from IPython.display import display
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the CSV file
file_path = "/content/train_u6lujuX_CVtuZ9i (1).csv"  # Update path if needed
df = pd.read_csv(file_path)

# Display the first few rows
print("First 5 rows:")
display(df.head())

# Check for null values
print("\nNull values per column:")
print(df.isnull().sum())

# Fill NaN values with 'null'
df.fillna("null", inplace=True)

# Display info
print("\nDataFrame info:")
df.info()

# Display descriptive statistics
print("\nDescriptive statistics:")
display(df.describe())

# Display column names
print("\nColumn names:")
print(df.columns)

# Drop duplicates
df.drop_duplicates(inplace=True)

# Plotting: Histogram (Corrected)
# Replace 'column_name' with an actual column name, like 'ApplicantIncome'
# You can replace 'ApplicantIncome' with any other valid column name from your dataframe
print("\nHistogram for ApplicantIncome:")
df['ApplicantIncome'].hist(bins=30) # Plots histogram
plt.xlabel('Applicant Income') # labels x axis
plt.ylabel('Frequency') # labels y axis
plt.title('Applicant Income Distribution') # creates title
plt.show()

# Plotting: Correlation heatmap (Corrected)
# Select only numeric columns for the correlation heatmap
numeric_df = df.select_dtypes(include=['number'])
# Checks to make sure there is more than one numeric column before creating heatmap
if numeric_df.shape[1] > 1:
  print("\nCorrelation Heatmap:")
  plt.figure(figsize=(10, 6))
  sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')
  plt.show()
else:
  print("\nNot enough numerical columns for correlation")

# Importing modules
from IPython import get_ipython
from IPython.display import display
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

# Load the CSV file
file_path = "/content/train_u6lujuX_CVtuZ9i (1).csv"  # Update path if needed
df = pd.read_csv(file_path)

# Display the first few rows
print("First 5 rows:")
display(df.head())

# Check for null values
print("\nNull values per column:")
print(df.isnull().sum())

# Fill NaN values with 'null'
df.fillna("null", inplace=True)

# Display info
print("\nDataFrame info:")
df.info()

# Display descriptive statistics
print("\nDescriptive statistics:")
display(df.describe())

# Display column names
print("\nColumn names:")
print(df.columns)

# Drop duplicates
df.drop_duplicates(inplace=True)

# Plotting: Histogram (Corrected)
# Replace 'column_name' with an actual column name, like 'ApplicantIncome'
# You can replace 'ApplicantIncome' with any other valid column name from your dataframe
print("\nHistogram for ApplicantIncome:")
df['ApplicantIncome'].hist(bins=30) # Plots histogram
plt.xlabel('Applicant Income') # labels x axis
plt.ylabel('Frequency') # labels y axis
plt.title('Applicant Income Distribution') # creates title
plt.show()

# Plotting: Correlation heatmap (Corrected)
# Select only numeric columns for the correlation heatmap
numeric_df = df.select_dtypes(include=['number'])
# Checks to make sure there is more than one numeric column before creating heatmap
if numeric_df.shape[1] > 1:
  print("\nCorrelation Heatmap:")
  plt.figure(figsize=(10, 6))
  sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')
  plt.show()
else:
  print("\nNot enough numerical columns for correlation")

# Correctly selecting the target column for train test split
# Replace 'Loan_Status' with the actual name of your target column
target_column_name = 'Loan_Status'
if target_column_name in df.columns:
  X = df.drop(target_column_name, axis=1)
  y = df[target_column_name]

  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
  print(f"\nSplit data into train and test sets based on target_column {target_column_name}")
  print(f"X_train shape: {X_train.shape}")
  print(f"y_train shape: {y_train.shape}")
  print(f"X_test shape: {X_test.shape}")
  print(f"y_test shape: {y_test.shape}")

else:
  print(f"\nError: '{target_column_name}' not found in columns. Please choose the right target column")
  print(f"Column names available: {df.columns.to_list()}")

df.to_csv("processed_data.csv", index=False)

from google.colab import files
files.download("processed_data.csv")

!pip install pandas matplotlib seaborn

import subprocess

subprocess.run(["pip", "install", "pandas", "matplotlib", "seaborn"])



import pandas as pd

# Load dataset
file_path = "/content/train_u6lujuX_CVtuZ9i (1).csv"  # Update if needed
df = pd.read_csv(file_path)

# Display first few rows
df.head()

df.isnull().sum()

df.fillna(method='ffill', inplace=True)

df.info()

df.info()

df = pd.get_dummies(df, drop_first=True)

# Importing modules
import pandas as pd
import subprocess

# Load dataset
file_path = "/content/train_u6lujuX_CVtuZ9i (1).csv"  # Update if needed
df = pd.read_csv(file_path)

# Display first few rows
print("First 5 rows:")
print(df.head())

# Check for null values
print("\nNull values per column:")
print(df.isnull().sum())

# Fill NaN values
df.fillna(method='ffill', inplace=True)

# Display info
print("\nDataFrame info after fillna:")
df.info()

# Extract the target variable BEFORE one hot encoding
y = df['Loan_Status']  # Target Variable
df = df.drop('Loan_Status', axis=1) # drops the column loan status before we one hot encode

# One hot encode all columns
df = pd.get_dummies(df, drop_first=True)

# Display info after one hot encoding
print("\nDataFrame info after get_dummies:")
df.info()

# Add target variable back to dataframe to see if it worked.
df['Loan_Status'] = y
# Display info after one hot encoding
print("\nDataFrame info after adding target variable back to dataframe:")
df.info()

# Define X by removing the target variable
X = df.drop('Loan_Status', axis=1) # X represents the features

print("\nX shape:")
print(X.shape)
print("\ny shape:")
print(y.shape)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Install necessary libraries
!pip install pandas scikit-learn

# Importing modules
import pandas as pd
import subprocess
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.impute import SimpleImputer # import SimpleImputer to fix NaN issues

# Load dataset
file_path = "/content/train_u6lujuX_CVtuZ9i (1).csv"  # Update if needed
df = pd.read_csv(file_path)

# Display first few rows
print("First 5 rows:")
print(df.head())

# Check for null values
print("\nNull values per column:")
print(df.isnull().sum())

# Fill NaN values
df.fillna(method='ffill', inplace=True)

# Display info
print("\nDataFrame info after fillna:")
df.info()

# Check for NaN values before one-hot encoding
print("\nNaN values before one-hot encoding:")
print(df.isnull().sum())

# Extract the target variable BEFORE one hot encoding
y = df['Loan_Status']  # Target Variable
df = df.drop('Loan_Status', axis=1) # drops the column loan status before we one hot encode

# One hot encode all columns
df = pd.get_dummies(df, drop_first=True)

# Display info after one hot encoding
print("\nDataFrame info after get_dummies:")
df.info()

# Check for NaN values after one-hot encoding
print("\nNaN values after one-hot encoding:")
print(df.isnull().sum())

# Impute NaN values with the mean if needed
if df.isnull().values.any():
    print("\nImputing NaN values after one-hot encoding...")
    imputer = SimpleImputer(strategy='mean')  # You can use 'median' or 'most_frequent' as well
    df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)
    print("\nNaN values after imputation:")
    print(df.isnull().sum())
else:
    print("\nNo NaN values found after one hot encoding. No imputation needed")

# Add target variable back to dataframe to see if it worked.
df['Loan_Status'] = y
# Display info after one hot encoding
print("\nDataFrame info after adding target variable back to dataframe:")
df.info()

# Define X by removing the target variable
X = df.drop('Loan_Status', axis=1) # X represents the features

print("\nX shape:")
print(X.shape)
print("\ny shape:")
print(y.shape)

# Check for NaN values in X
if X.isnull().values.any():
  print("X contains NaN values after processing")
  raise ValueError("X contains NaN values. Unable to continue training.")
else:
  print("\nX contains no NaN values. Proceeding to train test split")

# Train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Logistic Regression model
model = LogisticRegression(max_iter=1000)  # Increased max_iter
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluate Model
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))

from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

import joblib
joblib.dump(model, "loan_prediction_model.pkl")

model = joblib.load("loan_prediction_model.pkl")